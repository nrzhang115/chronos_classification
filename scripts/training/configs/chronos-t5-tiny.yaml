training_data_paths:
#- "/home/ubuntu/tsmixup-data.arrow"
- "/srv/scratch/z5298768/chronos_classification/tokenization_updated"
probability:
#- 0.9
- 0.1
context_length: 512
prediction_length: 0 # 64
min_past: 60
max_steps: 200_000
save_steps: 100_000
log_steps: 500
per_device_train_batch_size: 32
learning_rate: 0.001
optim: adamw_torch_fused
num_samples: 20
shuffle_buffer_length: False
gradient_accumulation_steps: 1
model_id: google/t5-efficient-tiny
model_type: classification # Change fro seq2seq
random_init: false # Change from true to false
tie_embeddings: false # Change from true to false
output_dir: /srv/scratch/z5298768/chronos_classification/t5_tiny_output
tf32: true
torch_compile: False
tokenizer_class: "MeanScaleUniformBins"
tokenizer_kwargs:
  low_limit: -15.0
  high_limit: 15.0
n_tokens: 4096
lr_scheduler_type: cosine # Change from linear
warmup_ratio: 0.1 # 0.0
dataloader_num_workers: 1
max_missing_prop: 0.9
use_eos_token: false # Change from true
evaluation_strategy: epoch
